# Based on https://github.com/AlignmentResearch/learned-planners/blob/main/k8s/runner.yaml

apiVersion: batch/v1
kind: Job
metadata:
  name: {NAME}
  labels:
    kueue.x-k8s.io/queue-name: farai
    wandb-project: {WANDB_PROJECT}
    wandb-entity: {WANDB_ENTITY}
    launch-id: {LAUNCH_ID}
spec:
  suspend: true
  template:
    metadata:
      generateName: {NAME}
    spec:
      priorityClassName: {PRIORITY}
      volumes:
        - name: robust-llm-storage
          persistentVolumeClaim:
            claimName: st-cloudflare-robust-llm
        - name: devshm
          emptyDir:
            medium: Memory
            sizeLimit: 4Gi
      containers:
        - name: devbox-container
          image: "ghcr.io/alignmentresearch/robust-llm:{CONTAINER_TAG}"
          command:
            - bash
            - -c
            - |
              git clone https://github.com/AlignmentResearch/robust-llm.git && cd robust-llm && git checkout {COMMIT_HASH} && git submodule update --recursive && {COMMAND}
          resources:
            requests:
              cpu: {CPU}
            limits:
              memory: {MEMORY}
              nvidia.com/gpu: {GPU}
          volumeMounts:
            - name: robust-llm-storage
              mountPath: /robust_llm_data
            # This is needed as for multi-GPU training, accelerate needs to write
            # to /dev/shm and the default size is too small
            - name: devshm
              mountPath: /dev/shm
          env:
            - name: GIT_ASKPASS
              value: "true"
            - name: GITHUB_PAT
              valueFrom:
                secretKeyRef:
                  name: github-credentials
                  key: pat
            - name: GIT_CONFIG_PARAMETERS
              value: "'credential.https://github.com.username=$(GITHUB_PAT)'"
            - name: WANDB_API_KEY
              valueFrom:
                secretKeyRef:
                  name: wandb
                  key: api-key
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: openai-api-key
                  key: key
                  optional: true  # Key only needed for StrongREJECT ScoringFn.
            - name: WANDB_ENTITY
              value: {WANDB_ENTITY}
            - name: WANDB_PROJECT
              value: {WANDB_PROJECT}
            - name: WANDB_MODE
              value: {WANDB_MODE}
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: huggingface
                  key: token
      # Never restart the pod. If the job retries, it will do so in a new pod.
      restartPolicy: Never
      imagePullSecrets:
        - name: docker
  # If the job fails, retry up to 3 times with a new pod.
  # Job failures can happen due to transient errors such as outage of external services
  # we pull/push data to (HuggingFace, W&B, ...).
  backoffLimit: 3
  # Don't count pod disruption such as preemption towards backoff target.
  # These are dependent on cluster weather, and not our code. See
  # https://kubernetes.io/docs/concepts/workloads/controllers/job/#pod-failure-policy
  podFailurePolicy:
    rules:
    - action: Ignore
      onPodConditions:
      - type: DisruptionTarget

version: 2.1

orbs:
  python: circleci/python@1.5.0
  codecov: codecov/codecov@3.3.0

executors:
  python-executor:
    docker:
      - image: cimg/python:3.10.13

commands:
  prepare-virtualenv:
    description: "Create Python virtual environment with caching support"
    steps:
      - restore_cache:
          # To force cache validation, increase the version number N in "venv-vN" below
          key: &venv-cache venv-v3-{{ checksum "pyproject.toml" }}
      - run:
          name: Setup Virtual Environment
          command: |
            # Store venv activate script in special CircleCI BASH_ENV
            # variable which will be automatically sourced before
            # new commands
            echo ". $(pwd)/venv/bin/activate" >> "$BASH_ENV"
            if [ ! -d "venv" ]; then
              # venv does not exist: create it
              python -m venv venv
              # Activate venv now it's been created
              source "$BASH_ENV"
              # Install CPU version of PyTorch as CI does not have GPU.
              # (CUDA version runs on CPU OK, but file size is larger,
              # slowing down CI.)
              pip install torch --index-url https://download.pytorch.org/whl/cpu
              # Install remaining dependencies.
              # Note if we ever remove `-e` it'll become necessary to reinstall
              # robust_llm even if a virtual environment already exists, with:
              # pip install --upgrade --force-reinstall --no-deps '.[dev,tensorflow]'
              pip install -e '.[dev,tensorflow]'
            fi

      - save_cache:
          paths:
            - "venv"
          key: *venv-cache

      - run:
          name: print installed packages
          command: pip freeze --all

  memory-monitor:
    description: "Monitor memory usage of processes in background"
    steps:
      - run:
          name: Memory Monitor
          command: |
            mkdir /tmp/resource-usage
            export FILE=/tmp/resource-usage/memory.txt
            while true; do
              ps eo pid,%cpu,%mem,args,uname --sort=-%mem >> $FILE
              echo "----------" >> $FILE
              sleep 1
            done
          background: true

  store-test-output:
    description: "Store the output of tests."
    steps:
      - store_artifacts:
          path: /tmp/test-reports
          destination: test-reports

      - store_test_results:
          path: /tmp/test-reports

  store-memory-monitor:
    description: "Store resource usage of tests"
    steps:
      - store_artifacts:
          path: /tmp/resource-usage
          destination: resource-usage

jobs:
  pytest:
    executor: python-executor
    parallelism: 4
    resource_class: xlarge
    steps:
      - checkout
      - prepare-virtualenv
      - run:
          name: Login to Weights & Biases
          command: |
            wandb login $WANDB_API_KEY
      - memory-monitor
      - run:
          name: Run tests
          command: |
            # Ensure that the script fails if any command fails
            set -euo pipefail
            # Here we split tests evenly by time across the parallel executors,
            # which requires some tedious parsing to get FULLTESTPATHS, the
            # subset of tests to run in this executor.

            # List all test functions in the specified directory
            TESTFUNCTIONS=$(pytest --collect-only -q | grep '::' | grep -v '<Module')
            echo "$TESTFUNCTIONS" > /tmp/node-ids.txt
            echo "TESTFUNCTIONS = $TESTFUNCTIONS"

            # Check for duplicates in TESTFUNCTIONS
            TOTAL_TESTFUNCTIONS=$(echo "$TESTFUNCTIONS" | wc -l)
            UNIQUE_TESTFUNCTIONS=$(echo "$TESTFUNCTIONS" | sort | uniq | wc -l)
            if [ "$TOTAL_TESTFUNCTIONS" -ne "$UNIQUE_TESTFUNCTIONS" ]; then
                echo "Error: TESTFUNCTIONS contains duplicates!"
                echo "Total test functions: $TOTAL_TESTFUNCTIONS"
                echo "Unique test functions: $UNIQUE_TESTFUNCTIONS"
                exit 1
            fi

            # Extract function names and save to a temporary file
            FUNCTIONNAMES=$(echo "$TESTFUNCTIONS" | sed -E 's/^.+:://')
            echo "$FUNCTIONNAMES" > /tmp/function-names.txt
            echo "FUNCTIONNAMES = $FUNCTIONNAMES"

            # Check for duplicates in FUNCTIONNAMES
            TOTAL_FUNCTIONNAMES=$(echo "$FUNCTIONNAMES" | wc -l)
            UNIQUE_FUNCTIONNAMES=$(echo "$FUNCTIONNAMES" | sort | uniq | wc -l)
            if [ "$TOTAL_FUNCTIONNAMES" -ne "$UNIQUE_FUNCTIONNAMES" ]; then
                echo "Error: FUNCTIONNAMES contains duplicates!"
                echo "Total test functions: $TOTAL_FUNCTIONNAMES"
                echo "Unique test functions: $UNIQUE_FUNCTIONNAMES"
                exit 1
            fi

            # Check if the number of test functions and function names matches
            if [ "$TOTAL_TESTFUNCTIONS" -ne "$TOTAL_FUNCTIONNAMES" ]; then
                echo "Error: Number of test functions and function names does not match!"
                echo "Total test functions: $TOTAL_TESTFUNCTIONS"
                echo "Total function names: $TOTAL_FUNCTIONNAMES"
                echo "List of test functions: $TESTFUNCTIONS"
                echo "List of function names: $FUNCTIONNAMES"
                exit 1
            fi

            # Split the function names by timings using CircleCI's test splitting feature
            SPLITFUNCTIONNAMES=$(circleci tests split --split-by=timings --timings-type=testname /tmp/function-names.txt)
            echo "SPLITFUNCTIONNAMES = $SPLITFUNCTIONNAMES"

            # Reconstruct the full test paths by matching the function names with the original list
            FULLTESTPATHS=$(echo "$SPLITFUNCTIONNAMES" | while read -r FUNCTIONNAME; do
              ESCAPED_FUNCTIONNAME=$(echo "$FUNCTIONNAME" | sed 's/[]\/$*.^|[]/\\&/g')
              grep "::$ESCAPED_FUNCTIONNAME$" /tmp/node-ids.txt;
            done)
            echo "FULLTESTPATHS = $FULLTESTPATHS"

            # Check if the number of split function names and full test paths matches
            TOTAL_SPLITFUNCTIONNAMES=$(echo "$SPLITFUNCTIONNAMES" | wc -l)
            TOTAL_FULLTESTPATHS=$(echo "$FULLTESTPATHS" | wc -l)

            if [ "$TOTAL_SPLITFUNCTIONNAMES" -ne "$TOTAL_FULLTESTPATHS" ]; then
                echo "Error: Number of split function names and full test paths does not match!"
                echo "Total split function names: $TOTAL_SPLITFUNCTIONNAMES"
                echo "Total full test paths: $TOTAL_FULLTESTPATHS"
                echo "List of split function names: $SPLITFUNCTIONNAMES"
                echo "List of full test paths: $FULLTESTPATHS"
                exit 1
            fi

            # Ensure the output directory exists
            mkdir -p /tmp/test-reports

            # Run pytest with the split test functions
            pytest --cov=robust_llm --cov=tests --junitxml=/tmp/test-reports/junit.xml --durations=500 -vv $(echo "$FULLTESTPATHS" | tr '\n' ' ')
      - codecov/upload
      - store-test-output
      - store-memory-monitor

  pytest-multigpu:
    executor: python-executor
    resource_class: alignmentresearch/far-2gpu-14cpu-60g
    # Unlike the `pytest` job, we don't use `parallelism` here since we don't
    # want to reserve lots of GPUs on the FAR cluster simultaneously, and the
    # FAR GPU resource classes only allow one concurrent instance anyway:
    # https://github.com/AlignmentResearch/flamingo/blob/e9b3bed7d02e3154dbc591820ab64f37e53f14ee/admin/main/circleci/README.md#gpu-enabled-classes
    steps:
      - checkout
      - prepare-virtualenv
      - memory-monitor
      - run:
          name: Run multigpu tests
          command: |
            mkdir -p /tmp/test-reports

            # Put error message of known flakes here.
            FLAKE_ERROR_MESSAGES=(
              # GH#826
              "FileNotFoundError: \[Errno 2\] No such file or directory: '/home/circleci/\.cache/huggingface/"
            )
            FLAKE_ERROR_REGEX=$(printf "%s\|" "${FLAKE_ERROR_MESSAGES[@]}")  # Join array elements with "\|"
            FLAKE_ERROR_REGEX=${FLAKE_ERROR_REGEX%\\|}  # Remove the trailing "\|"
            FLAKE_ERROR_REGEX="\($FLAKE_ERROR_REGEX\)"

            CYAN="\033[0;36m"
            RED="\033[0;31m"
            NO_COLOR="\033[0m"
            MAX_RETRIES=3
            for ((i = 0; i < MAX_RETRIES; i++)); do
              echo -e "${CYAN}----- Attempt $((i + 1)) -----${NO_COLOR}"

              LATEST_EXIT_CODE=0
              # --exitfirst: Although we'd prefer to see all test results,
              # sometimes only one process will fail a test (without printing
              # any output since pytest defers output until all tests are done)
              # and move on to the next test. Then the processes are out of sync
              # and hang until CI times out. Failing on the first test exits
              # quicker than hanging and prints the error.
              # Reducing the NCCL timeout instead of using --exitfirst fixes the
              # hanging but still does not print the error, since it kills both
              # processes before all tests are done.
              # || LATEST_EXIT_CODE=$?: Gets exit code upon failure but also
              # makes the overall exit code 0, which we want because otherwise
              # CI will immediately fail this step due to running with bash -e,
              # skipping our flake retry logic.
              ./tests/run_tests_with_accelerate.py --coverage -m multigpu --junitxml=/tmp/test-reports/junit-process-\$RANK.xml --durations=500 -vv --exitfirst || LATEST_EXIT_CODE=$?

              if [ "$LATEST_EXIT_CODE" -eq 0 ]; then
                exit 0
              elif grep --quiet "$FLAKE_ERROR_REGEX" /tmp/accelerate_tests_output/* ; then
                echo -e "${RED}Flaked with exit code $LATEST_EXIT_CODE${NO_COLOR}\n\n"
              else
                exit "$LATEST_EXIT_CODE"
              fi
            done
            echo "All retry attempts exhausted. Exiting with last exit code"
            exit "$LATEST_EXIT_CODE"
          environment:
            WANDB_MODE: offline
      - codecov/upload
      - store-test-output
      - store-memory-monitor

  lint:
    executor: python-executor
    steps:
      - checkout
      - prepare-virtualenv
      - run:
          name: black
          command: |
            black --version
            black . --check
      - run:
          name: isort
          command: |
            isort --version
            isort robust_llm --check --verbose
      - run:
          name: pyright
          command: |
            pyright --version
            pyright
      - run:
          name: mypy
          command: |
            mypy --version
            mypy --follow-imports=silent --show-error-codes --check-untyped-defs robust_llm/ tests/
      - run:
          name: autoflake
          command: |
            autoflake --version
            autoflake --in-place --remove-all-unused-imports --remove-duplicate-keys --remove-unused-variables -v --exclude venv --recursive .
      - run:
          name: flake8
          command: |
            flake8 --version
            flake8 . -v --exclude venv

workflows:
  version: 2
  tests:
    jobs:
      - pytest
      - pytest-multigpu
      - lint

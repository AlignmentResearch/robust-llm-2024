# @package _global_
defaults:
- /dataset: PasswordMatch/main
- /evaluation: DEFAULT
- /attack@evaluation.evaluation_attack: gcg-small
- /defense: PERPLEXITY
- /model@defense.decoder: pythia-14m
- /model: pythia-14m
- _self_

dataset:
  n_train: 2
  n_val: 2

defense:
  decoder:
    # Since we are looking at perplexity, we need a model that produces
    # logits over tokens.
    inference_type: "generation"
experiment_name: ???
run_name: ???
experiment_type: "evaluation"

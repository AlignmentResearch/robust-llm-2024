experiment_name: "perplexity_defense_imdb"
experiment_type: "evaluation"

environment:
  model_name_or_path: "AlignmentResearch/robust_llm_pythia-imdb-14m-mz-ada-v3"
  is_pythia: true
  decoder_name: "EleutherAI/pythia-14m"
  decoder_checkpoint: 143000

dataset:
  dataset_type: "AlignmentResearch/IMDB"
  n_val: 1000


evaluation:
  batch_size: 16
  evaluation_attack:
    attack_type: "random_token"
    append_to_modifiable_chunk: true
    random_token_attack_config:
      max_iterations: 40

defense:
  defense_type: "perplexity"
  num_preparation_examples: 500
  perplexity_defense_config:
    batch_size: 16

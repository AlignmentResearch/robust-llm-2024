# @package _global_
defaults:
- AdvTraining/short_adv_training_base
- /dataset: EnronSpam/main
- /model: EleutherAI/pythia-14m
- /attack@training.adversarial.training_attack: random-token-1280-its
- /attack@evaluation.evaluation_attack: random-token-1280-its
- _self_

environment:
    deterministic: true

model:
  name_or_path: AlignmentResearch/robust_llm_pythia-14m_clf_spam_v-ian-082_s-0

training:
  adversarial:
    max_adv_data_proportion: 0.75
    target_adversarial_success_rate: 0.5
    min_attack_iterations: 1280
    max_attack_iterations: 8192
    adv_sampling_decay: 0.001
    num_examples_to_generate_each_round: 250
    only_add_successful_adversarial_examples: False
    loss_rank_weight: 0.0
    training_attack:
      initial_n_its: 1280

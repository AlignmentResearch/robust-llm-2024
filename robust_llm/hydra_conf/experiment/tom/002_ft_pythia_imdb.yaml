# @package _global_
# based on ian/20240621_ft_pythia_large_imdb_test.yaml
defaults:
- /training: DEFAULT
- /dataset: IMDB/main
- /model: EleutherAI/pythia-160m
- _self_

experiment_type: "training"

dataset:
  n_train: 20000
  n_val: 200

model:
  train_minibatch_size: 2

training:
  logging_steps: 100
  save_to: BOTH
  num_train_epochs: 1
  learning_rate: 1e-5
  optimizer: "adafactor"
  save_strategy: "no"

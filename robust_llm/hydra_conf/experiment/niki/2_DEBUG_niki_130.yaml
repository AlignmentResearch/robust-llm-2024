# @package _global_
defaults:
- /training: DEFAULT
- /training/adversarial: DEFAULT
- /model: Default/clf/imdb/pythia-14m-s0
- /dataset: IMDB/stable
- /attack@training.adversarial.training_attack: RANDOM_TOKEN
- /attack@evaluation.evaluation_attack: RANDOM_TOKEN
- _self_

evaluation:
  num_iterations: 256

training:
  optimizer: "adafactor"
  num_train_epochs: 1
  learning_rate: 1e-5
  lr_scheduler_type: "constant"  # TODO: see if this works ok
  adversarial:
    num_examples_to_generate_each_round: 10
    max_augmented_data_size: 10
    num_adversarial_training_rounds: 4
    max_adv_data_proportion: 0.8
    loss_rank_weight: 0.5
    adv_sampling_decay: 0.005
    attack_schedule:
      start: 128
      end: 512  # TODO: re-check this

dataset:
  n_train: 100
  n_val: 20

experiment_type: "training"

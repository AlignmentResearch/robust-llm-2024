experiment_name: "retokenization_defense_example"
job_type: "defense"
experiment_type: "defense"

training:
  num_train_epochs: 1

environment:
  model_name: "textattack/bert-base-uncased-imdb"
  model_family: "bert"

dataset:
  dataset_type: "AlignmentResearch/IMDB"
  n_train: 10
  n_val: 10

defense:
  defense_type: "retokenization"
  retokenization_defense_config:
    drop_percentage: 0.2

evaluation:
  evaluation_attack:
    attack_type: "textfooler"
    text_attack_attack_config:
      query_budget: 400

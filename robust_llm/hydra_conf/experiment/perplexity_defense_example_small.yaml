experiment_name: "perplexity_defense_example"
experiment_type: "evaluation"

environment:
  model_name_or_path: "AlignmentResearch/robust_llm_pythia-imdb-14m-mz-ada-v3"
  model_family: "pythia"
  dataset_type: "hf/imdb"
  train_set_size: 10
  validation_set_size: 10
  shuffle_validation_set: true
  decoder_name: "EleutherAI/pythia-14m"
  decoder_family: "pythia"
  decoder_revision: "main"

evaluation:
  batch_size: 128
  num_generated_examples: 10
  evaluation_attack:
    attack_type: "random_token"
    random_token_attack_config:
      max_iterations: 4

defense:
  defense_type: "perplexity"
  num_preparation_examples: 10
  perplexity_defense_config:
    batch_size: 4
